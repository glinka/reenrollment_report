%% This document should serve as a base for most mathematically
%% oriented documents. There is probably a better way to do this.

\documentclass[12pt]{article}
%\renewcommand\thesubsection{\thesection.\alph{subsection}}
\usepackage{graphicx, subcaption, amsfonts, amsmath, amsthm, empheq, setspace, lscape}
\usepackage[toc,page]{appendix}
\newtheorem*{thm:jnf}{Jordan normal form for square matrices}
%% some new commands I have no idea how they work
% \doublespacing
\newcommand*\widefbox[1]{\fbox{\hspace{2em}#1\hspace{2em}}}
\newlength\dlf
\newcommand\alignedbox[2]{
  % Argument #1 = before & if there were no box (lhs)
  % Argument #2 = after & if there were no box (rhs)
  % Alignment sign of the line
  {
    \settowidth\dlf{$\displaystyle #1$}  
    % The width of \dlf is the width of the lhs, with a displaystyle font
    \addtolength\dlf{\fboxsep+\fboxrule}  
    % Add to it the distance to the box, and the width of the line of the box
    \hspace{-\dlf}  
    % Move everything dlf units to the left, so that & #1 #2 is aligned under #1 & #2
    \boxed{#1 #2}
    % Put a box around lhs and rhs
  }
}
%% end new commands I have no idea how they work
\newcommand\ER{Erd\H{o}s-R\'{e}nyi}
\newcommand{\K}[1]{\mathcal{K}^{#1}}
\newcommand{\Kk}{\mathcal{K}^k}
\newcommand{\Forall}{\; \forall \;}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\DeclareMathOperator*{\argmin}{\arg\!\min}
% \captionsetup{labelformat=empty,labelsep=none}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
% \setlength\parindent{0pt}
\graphicspath{ {./figs/} }
\pagestyle{plain}
\begin{document}
\title{\vspace{-1cm}Equation free analysis of a multigraph model and dimensionality reduction in sloppy models}
\author{\LARGE An overview by Alexander Holiday\vspace{3mm}\\\Large  under the supervision of\vspace{3mm}\\\LARGE  Professor Yannis Kevrekidis}
\date{03/25/2015}
\maketitle
\begin{spacing}{2}
\begin{abstract}
  Over the past year, a greatly improved coarse-projective integration scheme was developed for the dynamically evolving multigraph system presented a year prior. With this algorithmic advance came the ability to implement a coarse fixed-point solver capable of locating system stationary states. Additionally, DMAPS, in conjunction with a suitable distance measure between data points, was applied to the problem to confirm the underlying low-dimensional system. In a different direction, we have recently begun applying DMAPS to parameter sets in sloppy models with the aim of both aiding optimization in these settings and reducing model complexity.
\end{abstract}

\section*{Progress and future work}
\indent Three main areas of research have emerged over the past year: equation free modeling of dynamically evolving networks, dimensionality reduction of these network systems, and dimensionality reduction of models in which one or more parameters may take a wide range of values without significantly affecting model output, termed ``sloppy'' models \cite{Gutenkunst2007}. \\
\indent In the field of equation free modeling, coarse-projective integration (CPI) schemes were developed for a voting model and a multigraph model \cite{Rath2012} \cite{Durrett2012}, accelerating system simulations in both cases. Representative degree sequence trajectories for the multigraph model are shown in Figs. (\ref{mm:evo1}) and (\ref{mm:evo2}), and the lifting and restriction operations are outlined in Fig. (\ref{mm:schematic}). The error incurred in the CPI routine is shown in Fig. (\ref{mm:cpi}). A coarse Newton method was subsequently implemented for the multigraphs, enabling direct computation of stationary states. The decrease in error as the Newton method progresses is visible in Fig. (\ref{mm:newton}). \textbf{In the future, we wish to build off these methods to create a bifurcation tracking algorithm and to perform coarse optimization}. \\
\indent The dimensionality reduction technique DMAPS was successfully applied to the multigraph system, uncovering a low-dimensional embedding. In the process, we necessarily encountered the issue of defining a distance between data points when each point is itself a network. This was addressed by using a random-walk based measure shown in \cite{Rajendran2013}. The resulting embedding, shown in Fig. (\ref{mm:dmaps2}), reveals that though the system's initial conditions may vary, trajectories will eventually evolve to the same stationary state and thus be embedded in the same point. \textbf{Future plans in this direction involve developing a suitable metric in the context of the voting model in which nodes of the network are labeled}. \\
\indent Parameter reduction in sloppy models remains in an early stage. We have used DMAPS to uncover sloppy parameter directions and are working towards developing an embedding that retains the meangingful, tightly constrained parameters while removing the sloppy ones. Once this is accomplished, \textbf{we would like to devise a method of optimizing the model in this embedded space, eliminating the problems encountered when working with the full, sloppy model}. We are currently trying to use ideas from \cite{Dsilva} and \cite{Lafon2004} to generate useful embeddings. \\
\indent Apart from the future goals already mentioned, \textbf{we also look to improve on previous work done in the group in the area of mixed integer linear optimization as it applies to generating networks with prescribed properties} \cite{Gounaris2013}. We are interested in increasing the speed through more thorough preconditioning and by developing tighter convex relaxations of the constraints.

% \section*{Equation free modeling}
% The main focus has been on the evolving multigraph model detailed in \cite{Rath2012}. In brief, the system dynamics exhibit preferential attachment such that whichever nodes have a high number of connections, or ``degree'', at time $t$ are more likely to increase their degree at time $t+1$, while those with a small degree are less likely to increase their connection count. This is the ``rich-get-richer'' phenomenon found in many real-world networks. Regardless of the initial network configuration, these dynamics eventually bring the system to a stationary state sequence of degrees. Figs. (\ref{mm:evo1}) and (\ref{mm:evo2}) depict the evolution of degree sequence for two different initial conditions. 
% \subsection*{Coarse projective integration}
% As the degree sequence evolves smoothly and contains a good estimation of the state of this particular system by tracking just how ``rich'' and ``poor'' the individuals have become, it was investigated as a potential coarse variable for the model. However, in order to further reduce the problem's dimensionality, the sorted degree sequence was fit to a fifth-order polynomial and the fitted polynomial's coefficients recorded as a surrogate for the full, detailed system. Fig. (\ref{mm:schematic}) depicts this process of ``restricting'' the full scale system, a multigraph containing all the nodes and all the connections between them, to a suitable coarse system, a vector of polynomial coefficients arising from fitting the multigraph's degree sequence. The inverse process of ``lifting'', transforming the polynomial coefficients into a full network, is straightforward: first take $n$ evenly spaced evaluations of the complete polynomial and round to create a vector of $n$ integers: the new degree sequence. Then use a modified Havel-Hakimi algorithm, described here \cite{S.L.Hakimi1962}, to create a multigraph from this degree sequence. \\
% With the lifting and restriction operators defined as above, a CPI routine for the multigraph model was implemented. To evaluate its accuracy, trajectories of CPI-accelerated simulations were compared to those without CPI. Fig. (\ref{mm:cpi}) shows this relative error. The small errors incurred validate the CPI procedure which reduces the number of direct simulation steps by 40%.
% \subsection*{Coarse fixed point finding}
% The success of the CPI routine enabled a coarse Newton method. In such a scheme, matrix-vector products involving the Jacobian are approximated as directional derivatives, which are in turn estimated through finite differences. Our coarse Newton method successfully locates the multigraph's stationary states, which would otherwise be found through expensive direct simulation. If we denote by $d^{(k)}$ the sorted degree sequence at iteration $k$ and define the error at $k$ as $e^{(k)} = d^{(k)} - d^{(k-1)}$, then Fig. (\ref{mm:newton}) shows the error in the 1-norm of $e^{(k)}$ as the solution progresses.
% \subsection*{Dimensionality reduction}
% The DMAPS algorithm was used to uncover a low-dimensional embedding of the multigraph system. To do this, it was necessary to define some notion of similarity between two different graphs. Our approach, based on \cite{Rajendran2013}, was to compare distributions of random walks over each graph. The reasoning is simple: if the distributions of random walkers were similar, the underlying networks would be likely also be similar. When combined with this distance measure, DMAPS did uncover a low-dimensional description of the multigraph system. Figs. (\ref{mm:dmaps1}) and (\ref{mm:dmaps2}) show embeddings from data taken over two different timescales. In the Fig. (\ref{mm:dmaps1}), two graphs initialized with very different initial conditions were sampled over a short $n^2$ timescale. Here we clearly see two distinct one-dimensional embeddings for each initial condition. However, as these graphs evolved they approached identical stationary states. Thus, when sampled over long timescales we would expect their embeddings to converge on a point. This is exactly the behavior exhibited in Fig. (\ref{mm:dmaps2}).
% \section*{Sloppy models}
% In the course of fitting models to data, it has been observed that their are often parameters such that, even when their values are varied over many orders of magnitude, the model's predictions do not change. These poorly constrained parameters are termed ``sloppy'', and the models they arise in ``sloppy models'' \cite{Gutenkunst2007}. Optimization in this setting is challenging, as traditional gradient descent algorithms become trapped in shallow valleys spanned by these sloppy directions, causing slow convergence to the minimum. Our goal is to combine DMAPS with a distance metric between points that captures information about the underlying optimization process. Hopefully the resulting embedding of parameter space would provide a better environment for optimization, one in which the sloppy directions were no longer present. We are currently trying to use ideas from \cite{Dsilva} and \cite{Lafon2004} to generate useful embeddings.
% \section*{Network generation}
% Applying mixed integer linear programming (MILP) to the problem of generating networks with prescribed properties led to the first general-purpose network generation algorithm capable of addressing an arbitrary number of desired network constraints \cite{Gounaris2013}. While the generality of the method was a major step forward, it suffers from slow runtimes for most problem sizes of interest; thus, we are interested in increasing the speed through more thorough problem preconditioning and by developing tighter convex relaxations of the constrains.
% \section*{Summary of future work}
% \begin{enumerate}
% \item Develop distance measure for labeled graphs suitable for application in the voting model
% \item Develop distance measure for sloppy parameter spaces that captures both meaningful parameters and optimization information
% \item Continue work on MILP network generation algorithm to enhance speed and to provide further examples of possible network properties that can be addressed
% \end{enumerate}
\end{spacing}

\include{reenrollment_figs}

\bibliographystyle{abbrv}
\bibliography{$HOME/Documents/bibTex/library}


\end{document}

